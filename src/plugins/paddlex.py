import base64
import json
import os
import time
from pathlib import Path
from typing import Any

import requests

if __name__ == "__main__":
    import typer
    from loguru import logger
else:
    from src.utils import logger


class PaddleXLayoutParser:
    """PaddleX ç‰ˆé¢è§£ææœåŠ¡å®¢æˆ·ç«¯"""

    def __init__(self, base_url: str = "http://localhost:8080"):
        self.base_url = base_url.rstrip("/")
        self.endpoint = f"{self.base_url}/layout-parsing"

    def encode_file_to_base64(self, file_path: str) -> str:
        with open(file_path, "rb") as file:
            encoded = base64.b64encode(file.read()).decode("utf-8")
            return encoded

    def _process_file_input(self, file_input: str) -> str:
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
        if os.path.exists(file_input):
            logger.info(f"ğŸ“ æ£€æµ‹åˆ°æœ¬åœ°æ–‡ä»¶: {file_input}")
            logger.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(file_input) / 1024 / 1024:.2f} MB")

            try:
                # å°†æœ¬åœ°æ–‡ä»¶ç¼–ç ä¸ºBase64
                encoded_content = self.encode_file_to_base64(file_input)
                logger.info(f"âœ… æ–‡ä»¶å·²ç¼–ç ä¸ºBase64ï¼Œé•¿åº¦: {len(encoded_content)} å­—ç¬¦")
                return encoded_content
            except Exception as e:
                logger.error(f"âŒ æ–‡ä»¶ç¼–ç å¤±è´¥: {e}")
                raise

        # æ£€æŸ¥æ˜¯å¦ä¸ºURL
        elif file_input.startswith(("http://", "https://")):
            logger.info(f"ğŸŒ æ£€æµ‹åˆ°URL: {file_input}")
            return file_input

        # å¦åˆ™å‡è®¾ä¸ºBase64ç¼–ç å†…å®¹
        else:
            logger.info(f"ğŸ“ å‡è®¾ä¸ºBase64ç¼–ç å†…å®¹ï¼Œé•¿åº¦: {len(file_input)} å­—ç¬¦")
            return file_input

    def layout_parsing(
        self,
        file_input: str,
        file_type: int | None = None,
        use_textline_orientation: bool | None = None,
        use_seal_recognition: bool | None = None,
        use_table_recognition: bool | None = None,
        use_formula_recognition: bool | None = None,
        use_chart_recognition: bool | None = None,
        use_region_detection: bool | None = None,
        layout_threshold: float | None = None,
        layout_nms: bool | None = None,
        use_doc_orientation_classify: bool = True,
        use_doc_unwarping: bool | None = False,
        use_wired_table_cells_trans_to_html: bool = True,  # å¯ç”¨åˆ™ç›´æ¥åŸºäºæœ‰çº¿è¡¨å•å…ƒæ ¼æ£€æµ‹ç»“æœçš„å‡ ä½•å…³ç³»æ„å»ºHTMLã€‚
        **kwargs,
    ) -> dict[str, Any]:
        """
        è°ƒç”¨ç‰ˆé¢è§£æAPIï¼šhttps://paddlepaddle.github.io/PaddleX/latest/pipeline_usage/tutorials/ocr_pipelines/PP-StructureV3.html#22-python
        """
        # å¤„ç†æ–‡ä»¶è¾“å…¥ï¼šæ£€æµ‹æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
        processed_file_input = self._process_file_input(file_input)
        payload = {"file": processed_file_input}

        # æ·»åŠ å¯é€‰å‚æ•°
        optional_params = {
            "fileType": file_type,
            "useDocOrientationClassify": use_doc_orientation_classify,
            "useDocUnwarping": use_doc_unwarping,
            "useTextlineOrientation": use_textline_orientation,
            "useSealRecognition": use_seal_recognition,
            "useTableRecognition": use_table_recognition,
            "useFormulaRecognition": use_formula_recognition,
            "useChartRecognition": use_chart_recognition,
            "useRegionDetection": use_region_detection,
            "layoutThreshold": layout_threshold,
            "layoutNms": layout_nms,
            "useWiredTableCellsTransToHtml": use_wired_table_cells_trans_to_html,
        }

        # æ·»åŠ éç©ºå‚æ•°
        for key, value in optional_params.items():
            if value is not None:
                payload[key] = value

        # æ·»åŠ å…¶ä»–kwargså‚æ•°
        for key, value in kwargs.items():
            if value is not None:
                payload[key] = value

        try:
            response = requests.post(
                self.endpoint, json=payload, headers={"Content-Type": "application/json"}, timeout=300
            )

            if response.status_code == 200:
                result = response.json()
                logger.info("âœ… è¯·æ±‚æˆåŠŸ!")
                return result
            else:
                logger.error(f"âŒ è¯·æ±‚å¤±è´¥! {self.endpoint}")
                try:
                    error_result = response.json()
                    logger.error(f"é”™è¯¯ä¿¡æ¯: {json.dumps(error_result, indent=2, ensure_ascii=False)}")
                    return error_result
                except Exception as e:
                    logger.error(f"å“åº”å†…å®¹: {response.text}")
                    return {"error": f"{e}: {response.text}", "status_code": response.status_code}

        except requests.exceptions.RequestException as e:
            health_check_response = requests.get(f"{self.base_url}/health", timeout=5)
            logger.error(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}: {health_check_response.json()}")
            return {"error": str(e)}

        except Exception as e:
            logger.error(f"âŒ å…¶ä»–å¼‚å¸¸: {e}")
            return {"error": str(e)}


def _parse_recognition_result(api_result: dict[str, Any], file_path: str) -> dict[str, Any]:
    # åŸºæœ¬ä¿¡æ¯
    parsed_result = {
        "success": True,
        "file_path": file_path,
        "file_name": os.path.basename(file_path),
        "log_id": api_result.get("logId"),
        "total_pages": 0,
        "pages": [],
        "full_text": "",
        "summary": {},
    }

    result_data = api_result.get("result", {})
    layout_results = result_data.get("layoutParsingResults", [])
    data_info = result_data.get("dataInfo", {})

    # æ•°æ®ä¿¡æ¯
    parsed_result["total_pages"] = len(layout_results)
    parsed_result["document_info"] = {
        "type": data_info.get("type", "unknown"),
        "total_pages": data_info.get("numPages", len(layout_results)),
        "page_dimensions": data_info.get("pages", []),
    }

    # ç»Ÿè®¡ä¿¡æ¯
    total_elements = 0
    total_tables = 0
    total_formulas = 0
    total_charts = 0
    total_seals = 0
    all_text_content = []

    # è§£ææ¯é¡µç»“æœ
    for page_index, page_result in enumerate(layout_results):
        page_info = {"page_number": page_index + 1, "content": {}, "statistics": {}}

        # Markdownå†…å®¹
        if "markdown" in page_result:
            markdown = page_result["markdown"]
            page_info["content"]["markdown_text"] = markdown.get("text", "")
            page_info["content"]["images"] = list(markdown.get("images", {}).keys())
            page_info["content"]["is_paragraph_start"] = markdown.get("isStart", False)
            page_info["content"]["is_paragraph_end"] = markdown.get("isEnd", False)

            # æ”¶é›†æ–‡æœ¬å†…å®¹
            if markdown.get("text"):
                all_text_content.append(markdown["text"])

        # è¯¦ç»†è¯†åˆ«ç»“æœ
        if "prunedResult" in page_result:
            pruned = page_result["prunedResult"]

            # ç‰ˆé¢æ£€æµ‹
            layout_detection = pruned.get("layout_detection", [])
            page_info["statistics"]["layout_elements"] = len(layout_detection)
            total_elements += len(layout_detection)

            # OCRç»“æœ
            ocr_result = pruned.get("ocr_result", [])
            page_info["statistics"]["ocr_elements"] = len(ocr_result)

            # è¡¨æ ¼è¯†åˆ«
            table_result = pruned.get("table_result", [])
            page_info["statistics"]["tables"] = len(table_result)
            total_tables += len(table_result)

            # å…¬å¼è¯†åˆ«
            formula_result = pruned.get("formula_result", [])
            page_info["statistics"]["formulas"] = len(formula_result)
            total_formulas += len(formula_result)

            # å›¾è¡¨è¯†åˆ«
            chart_result = pruned.get("chart_result", [])
            page_info["statistics"]["charts"] = len(chart_result)
            total_charts += len(chart_result)

            # å°ç« è¯†åˆ«
            seal_result = pruned.get("seal_result", [])
            page_info["statistics"]["seals"] = len(seal_result)
            total_seals += len(seal_result)

            # è¯¦ç»†å…ƒç´ ä¿¡æ¯
            page_info["content"]["layout_elements"] = layout_detection
            page_info["content"]["ocr_elements"] = ocr_result
            page_info["content"]["tables"] = table_result
            page_info["content"]["formulas"] = formula_result
            page_info["content"]["charts"] = chart_result
            page_info["content"]["seals"] = seal_result

        parsed_result["pages"].append(page_info)

    # æ±‡æ€»å…¨æ–‡å†…å®¹
    parsed_result["full_text"] = "\n\n".join(all_text_content)

    # æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯
    parsed_result["summary"] = {
        "total_elements": total_elements,
        "total_tables": total_tables,
        "total_formulas": total_formulas,
        "total_charts": total_charts,
        "total_seals": total_seals,
        "total_characters": len(parsed_result["full_text"]),
        "average_elements_per_page": round(total_elements / max(1, len(layout_results)), 2),
    }

    return parsed_result


def analyze_document(file_path: str, base_url: str = "http://localhost:8080") -> dict[str, Any]:
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        return {"success": False, "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", "file_path": file_path}

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = PaddleXLayoutParser(base_url=base_url)

    # åˆ¤æ–­æ–‡ä»¶ç±»å‹
    file_ext = os.path.splitext(file_path)[1].lower()
    if file_ext == ".pdf":
        file_type = 0
    elif file_ext in [".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".tif"]:
        file_type = 1
    else:
        return {"success": False, "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}", "file_path": file_path}

    logger.info(f"ğŸ“„ å¼€å§‹åˆ†ææ–‡æ¡£: {os.path.basename(file_path)}")
    logger.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(file_path) / 1024 / 1024:.2f} MB")
    logger.info(f"ğŸ“‹ æ–‡ä»¶ç±»å‹: {'PDF' if file_type == 0 else 'å›¾ç‰‡'}")

    try:
        # è°ƒç”¨APIè¿›è¡Œè¯†åˆ«
        result = client.layout_parsing(file_input=file_path, file_type=file_type)

        # æ£€æŸ¥APIè°ƒç”¨æ˜¯å¦æˆåŠŸ
        if result.get("errorCode") != 0:
            return {
                "success": False,
                "error": result.get("errorMsg", "APIè°ƒç”¨å¤±è´¥"),
                "file_path": file_path,
                "raw_result": result,
            }

        # è§£æç»“æœ
        analysis_result = _parse_recognition_result(result, file_path)
        return analysis_result

    except Exception as e:
        return {"success": False, "error": f"å¤„ç†å¼‚å¸¸: {str(e)}", "file_path": file_path}


def check_paddlex_health(base_url: str = "http://localhost:8080") -> bool:
    return requests.get(f"{base_url}/health", timeout=5)


def analyze_folder(input_dir: str, output_dir: str, base_url: str = "http://localhost:8080"):
    """åˆ†ææ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ”¯æŒæ–‡ä»¶ï¼Œä¿å­˜ä¸ºtxtæ ¼å¼"""
    input_path = Path(input_dir)
    output_path = Path(output_dir)

    if not input_path.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨ï¼š{input_dir}")
        return

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.mkdir(parents=True, exist_ok=True)

    # è·å–æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
    supported_extensions = {".pdf", ".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".tif"}
    files = []
    for root, dirs, filenames in os.walk(input_dir):
        for filename in filenames:
            file_path = Path(root) / filename
            if file_path.suffix.lower() in supported_extensions:
                files.append(file_path)

    if not files:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")

    success_count = 0
    for i, file_path in enumerate(files, 1):
        print(f"ğŸ”„ [{i}/{len(files)}] {file_path.name}")

        try:
            # åˆ†ææ–‡æ¡£
            result = analyze_document(str(file_path), base_url)

            if result.get("success"):
                # ä¿æŒç›®å½•ç»“æ„
                relative_path = file_path.relative_to(input_path)
                output_file = output_path / relative_path.with_suffix(".txt")
                output_file.parent.mkdir(parents=True, exist_ok=True)

                # å†™å…¥æ–‡æœ¬å†…å®¹
                text_content = (
                    result.get("full_text", "æœªæå–åˆ°å†…å®¹")
                    if result.get("success")
                    else f"åˆ†æå¤±è´¥ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                )
                with open(output_file, "w", encoding="utf-8") as f:
                    f.write(text_content)

                success_count += 1
                print(f"âœ… {output_file.name}")
            else:
                print(f"âŒ å¤±è´¥: {result.get('error')}")

        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {str(e)}")

        time.sleep(0.5)

    print(f"\nğŸ“Š å®Œæˆï¼æˆåŠŸ: {success_count}, æ€»è®¡: {len(files)}")


if __name__ == "__main__":
    app = typer.Typer(help="PaddleX æ–‡æ¡£åˆ†æå·¥å…·")

    @app.command()
    def single(file_path: str, base_url: str = "http://172.19.13.5:8080"):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        result = analyze_document(file_path, base_url)
        if result["success"]:
            print(f"âœ… æˆåŠŸæå– {len(result['full_text'])} ä¸ªå­—ç¬¦")
        else:
            print(f"âŒ å¤±è´¥: {result.get('error')}")

    @app.command()
    def folder(input_dir: str, output_dir: str, base_url: str = "http://172.19.13.5:8080"):
        """æ‰¹é‡åˆ†ææ–‡ä»¶å¤¹"""
        analyze_folder(input_dir, output_dir, base_url)

    app()
